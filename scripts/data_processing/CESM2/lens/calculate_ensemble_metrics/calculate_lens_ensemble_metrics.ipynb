{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_list = [\"ensemble_1001_001\", \"ensemble_1011_001\", \"ensemble_1021_001\", \"ensemble_1031_002\", \"ensemble_1041_001\", \"ensemble_1051_003\", \"ensemble_1061_001\", \"ensemble_1071_004\", \"ensemble_1081_001\", \"ensemble_1091_005\", \"ensemble_1101_001\",\n",
    "                 \"ensemble_1111_006\", \"ensemble_1121_001\", \"ensemble_1131_007\", \"ensemble_1141_001\", \"ensemble_1151_008\", \"ensemble_1161_001\", \"ensemble_1171_009\", \"ensemble_1181_001\", \"ensemble_1191_010\",\n",
    "                 \"ensemble_1231_001\", \"ensemble_1251_001\", \"ensemble_1281_001\", \"ensemble_1301_001\", \"ensemble_1301_002\", \"ensemble_1301_010\", \"ensemble_1301_011\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level_tux': {'global_mean': -3.9094611618755137e-20, 'global_std': 0.19905465166576986}, 'level_tuy': {'global_mean': 1.7936438524139273e-20, 'global_std': 0.13234788275774506}, 'level_0': {'global_mean': -1.4607491879568907e-17, 'global_std': 0.6707193411666164}, 'level_11': {'global_mean': 4.809813862225758e-19, 'global_std': 0.9499027942590248}, 'level_14': {'global_mean': -1.1246988115251005e-17, 'global_std': 0.9049123856449006}, 'level_1': {'global_mean': 6.5882962321022365e-18, 'global_std': 0.6708457100967729}, 'level_3': {'global_mean': 6.049085615681659e-18, 'global_std': 0.7219668185682295}, 'level_5': {'global_mean': -1.404773589676592e-17, 'global_std': 0.8409158748930468}, 'level_8': {'global_mean': -1.8972213187577904e-18, 'global_std': 0.911882499347164}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def parallel_variance(n_a, avg_a, M2_a, n_b, avg_b, M2_b):\n",
    "    \"\"\" Combines two sets of statistics (size, mean, and M2) to calculate a combined variance. \"\"\"\n",
    "    n = n_a + n_b\n",
    "    delta = avg_b - avg_a\n",
    "    M2 = M2_a + M2_b + delta**2 * n_a * n_b / n\n",
    "    var_ab = M2 / (n - 1) if n > 1 else 0  # Bessel's correction for unbiased estimator\n",
    "    return var_ab, M2, n\n",
    "\n",
    "def calculate_global_mean_std_parallel(ensemble_dict):\n",
    "    \"\"\"\n",
    "    Calculates the global mean and standard deviation over multiple ensembles for each level using a parallel algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    ensemble_dict (defaultdict of dict): A defaultdict where each key is a level and the value is\n",
    "                                         a dictionary containing two lists ('mean' and 'std') representing\n",
    "                                         the means and standard deviations for different ensembles at that level.\n",
    "\n",
    "    Returns:\n",
    "    final_stats (dict): A dictionary where each key is a level, and the value is a dictionary\n",
    "                        containing 'global_mean' and 'global_std' for that level.\n",
    "    \"\"\"\n",
    "\n",
    "    final_stats = {}\n",
    "\n",
    "    # Iterate over each level in the ensemble_dict\n",
    "    for level, stats in ensemble_dict.items():\n",
    "        means = stats['mean']\n",
    "        stds = stats['std']\n",
    "        n_ensembles = len(means)\n",
    "        \n",
    "        # Initialize for parallel variance calculation\n",
    "        global_mean = means[0]\n",
    "        M2 = 0\n",
    "        n = 1\n",
    "\n",
    "        # Accumulate global mean and variance in parallel\n",
    "        for i in range(1, n_ensembles):\n",
    "            n_a = n\n",
    "            n_b = 1  # Each ensemble has weight 1 (equal sample sizes)\n",
    "\n",
    "            avg_a = global_mean\n",
    "            avg_b = means[i]\n",
    "\n",
    "            # Calculate M2 (sum of squares of differences from the mean) for each ensemble\n",
    "            M2_b = stds[i] ** 2\n",
    "\n",
    "            # Combine statistics for the current ensemble with the global statistics so far\n",
    "            var_ab, M2, n = parallel_variance(n_a, avg_a, M2, n_b, avg_b, M2_b)\n",
    "            global_mean = (n_a * avg_a + n_b * avg_b) / n  # Updated global mean\n",
    "\n",
    "        # Final global standard deviation is the square root of the combined variance\n",
    "        global_std = np.sqrt(var_ab)\n",
    "\n",
    "        # Store the results for this level\n",
    "        final_stats[f\"level_{level}\"] = {\n",
    "            \"global_mean\": global_mean,\n",
    "            \"global_std\": global_std\n",
    "        }\n",
    "\n",
    "    return final_stats\n",
    "\n",
    "def calculate_global_mean_std(ensemble_list, data_dict, levels=[\"0\", \"1\", \"3\", \"5\", \"8\", \"11\", \"14\", 'tux', 'tuy', 'sst', 'ssh']):\n",
    "\n",
    "    # Initialize a dictionary to store the global mean and std for each level\n",
    "    global_stats = defaultdict(lambda: {\"mean\": [], \"std\": []})\n",
    "    \n",
    "    # Iterate through each key in the data dictionary\n",
    "    for key, value in data_dict.items():\n",
    "        # Split the key to extract the ensemble and level\n",
    "        parts = key.split('_')\n",
    "        ensemble = '_'.join(parts[:3])  # e.g., \"ensemble_1001_001\"\n",
    "        # Extract the level number, assuming \"levelX\" or \"levelXX\" format\n",
    "        #level_str = parts[-1].replace('level', '')  # Remove the \"level\" part\n",
    "        level_str = parts[-1].replace('a', '')  # Remove the \"a\" part\n",
    "        level = level_str  # Convert the remaining part to an integer\n",
    "\n",
    "        # Check if the ensemble is in the input list and the level is one of the levels of interest\n",
    "        if ensemble in ensemble_list and level in levels:\n",
    "            # Append the mean and std from the dictionary for that level\n",
    "            global_stats[level][\"mean\"].append(value[\"mean\"])\n",
    "            global_stats[level][\"std\"].append(value[\"std\"])\n",
    "\n",
    "    # Calculate the global mean and std for each level\n",
    "    final_stats = calculate_global_mean_std_parallel(global_stats)\n",
    "\n",
    "    return final_stats\n",
    "\n",
    "# Open and read the file\n",
    "with open('C:/Users/felix/PycharmProjects/deeps2a-enso/scripts/data_processing/CESM2/lens/calculate_ensemble_metrics/ensemble_stats_1_2_all.txt', 'r') as file:\n",
    "    data_dict = json.load(file)\n",
    "\n",
    "# Example usage\n",
    "global_stats = calculate_global_mean_std(ensemble_list, data_dict)\n",
    "print(global_stats)\n",
    "\n",
    "# Save the resulting dictionary to a file\n",
    "with open('global_stats_1_1grid.json', 'w') as outfile:\n",
    "    json.dump(global_stats, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
